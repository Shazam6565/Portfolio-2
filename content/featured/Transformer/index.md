---
date: '2'
title: 'Transformer -Text Completion Model'
cover: './transformer.png'
github: 'https://github.com/Shazam6565/Shazam-GPT'
external: '/Transformer_Implementation_Report(1).pdf'
tech:
  - Python
  - PyTorch
  - TensorFlow
  - C++ [GPU]
---

Developed a text completion model in Python from scratch using the Transformer architecture, inspired by the groundbreaking [Attention Is All You Need](https://arxiv.org/abs/1706.03762) research paper. This work forms the core foundation of large language models (LLMs) such as GPT-3, BERT, and BART.


